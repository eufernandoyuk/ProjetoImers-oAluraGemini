{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwbQIjgFCeGoBfJsJf32Ud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eufernandoyuk/ProjetoImers-oAluraGemini/blob/main/Aula_Alura_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vUzcl2dMnbC0"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the python SDK\n",
        "import google.generativeai as genai\n",
        "#use to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = \"AIzaSyAgbr0BIa1e_OAR0T0MxUo4EZL5yqW4l04\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "9MMJarwOpuhJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INICIALIZAR O MODELO GENERATIVO"
      ],
      "metadata": {
        "id": "dB997x9vrOqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "dpmKMiNNrRpK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "RZIPyjs3r5Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "VDjUs7KVuFXn",
        "outputId": "e8a8fc7f-0b82-4df3-822b-54eee08cb816"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  generation_config = {\n",
        "      'candidate_count':1,\n",
        "      'temperature':0.5,\n",
        "\n",
        "  }\n",
        ""
      ],
      "metadata": {
        "id": "msjOFXE_vwKF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações de segurança"
      ],
      "metadata": {
        "id": "O0Y16Uwdx8fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE'\n",
        "}"
      ],
      "metadata": {
        "id": "itRTiD9ox3y5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INICIALIZANDO O MODELO\n",
        "model= genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                             generation_config=generation_config,\n",
        "                             safety_settings=safety_settings\n",
        "                             )"
      ],
      "metadata": {
        "id": "vUZTZnSJy0qH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Aprender conteúdo de AI - dê exemplos')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "HmtgjIxB0jKW",
        "outputId": "2284617c-474e-4ded-faef-305eb761acfa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Conceitos Fundamentais de IA**\n",
            "\n",
            "* Aprendizado de Máquina\n",
            "* Aprendizado Profundo\n",
            "* Processamento de Linguagem Natural\n",
            "* Visão Computacional\n",
            "* Robótica\n",
            "\n",
            "**Técnicas de Aprendizado de Máquina**\n",
            "\n",
            "* Regressão\n",
            "* Classificação\n",
            "* Agrupamento\n",
            "* Árvore de Decisão\n",
            "* Máquinas de Vetores de Suporte\n",
            "\n",
            "**Modelos de Aprendizado Profundo**\n",
            "\n",
            "* Redes Neurais Convolucionais (CNNs)\n",
            "* Redes Neurais Recorrentes (RNNs)\n",
            "* Transformadores\n",
            "* Redes Adversariais Generativas (GANs)\n",
            "\n",
            "**Aplicações de IA**\n",
            "\n",
            "* Reconhecimento de Imagem\n",
            "* Processamento de Linguagem Natural\n",
            "* Diagnóstico Médico\n",
            "* Previsão Financeira\n",
            "* Veículos Autônomos\n",
            "\n",
            "**Ferramentas e Bibliotecas de IA**\n",
            "\n",
            "* TensorFlow\n",
            "* PyTorch\n",
            "* Keras\n",
            "* Scikit-learn\n",
            "* NLTK\n",
            "\n",
            "**Exemplos Práticos de IA**\n",
            "\n",
            "* **Reconhecimento de Imagem:** Identificar objetos em imagens, como carros, rostos e animais.\n",
            "* **Processamento de Linguagem Natural:** Entender e gerar texto, como tradução de idiomas e resumo de texto.\n",
            "* **Diagnóstico Médico:** Auxiliar médicos no diagnóstico de doenças, analisando imagens médicas e dados de pacientes.\n",
            "* **Previsão Financeira:** Prever tendências do mercado de ações e identificar oportunidades de investimento.\n",
            "* **Veículos Autônomos:** Controlar veículos sem intervenção humana, usando sensores e algoritmos de IA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CRIAR CHATBOT\n",
        "chat = model.start_chat(history=[])\n",
        "prompt =input('inserir prompt')\n",
        "\n",
        "while prompt != 'fim':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('Resposta:', response.text, '\\n')\n",
        "  prompt =input('inserir prompt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "jXELe1qD1i12",
        "outputId": "6b457578-d1c5-414d-e143-b95a53b55ec9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inserir promptQual a capital das Filipinas\n",
            "Resposta Manila \n",
            "\n",
            "inserir promptQual a comida típica desse país?\n",
            "Resposta Adobo \n",
            "\n",
            "inserir promptdo que é feita essa comida?\n",
            "Resposta Carne de porco ou frango, cozidos lentamente em molho de vinagre, molho de soja, alho, folhas de louro e pimenta \n",
            "\n",
            "inserir promptfim\n"
          ]
        }
      ]
    }
  ]
}